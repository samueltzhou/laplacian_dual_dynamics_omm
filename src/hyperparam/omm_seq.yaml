d: 11
n_samples: 200000 # normally 200000 (1 million in big experiment)
batch_size: 1024
discount: 0.9
log_dir: '/tmp/rl_laprepr/log'
total_train_steps: 20000 # normally 20000 (80000 in big experiment)
print_freq: 200
save_freq: 10000
max_episode_steps: 50
seed: 1234
env_name: GridRoom-1
env_family: Grid-v0
device: cpu
lr: 0.001
use_lr_schedule: False
linear_warmup: False # very helpful for initial training stability, fixed at first 10% of training steps
final_lr_multiplier: 0.05
use_wandb: True
hidden_dims:
  - 256
  - 256
  - 256
activation: relu
use_layer_norm: False
eigval_precision_order: 16
reduction_factor: 1
permute_step: 200000
direct_rotation: True
save_eig: True
save_model: False
save_model_every: 100000
do_plot_eigenvectors: True
obs_mode: xy
window_size: 128
algorithm: seq_omm
asymmetric_normalization: False
coefficient_normalization: False
eigenvalue_shift_alpha: 0.0
